# This role will install kubernetes on the specified hosts
# When this role is applied to a host group, it will
# look for some vars for each host and install the different k8s components based on those vars
# Here is the list of all the host variables that MUST be defined in order for this role
# to work correctly:
#   - K8S_MASTER - boolean - hostvar: Will flag this host as a k8s master server
#   - K8S_WORKER - boolean - hostvar: Will flag this host as a k8s worker server
#   - ETCD2 - boolean - hostvar: Will flag this host as an ETCD2 server for the k8s cluster

---

- name: Create directories
  become: True
  file:
    path: "{{ item }}"
    owner: root
    group: root
    mode: 0755
    state: directory
  with_items:
    - /opt/bin
    - /etc/kubernetes/ssl
    - /etc/kubernetes/manifests
    - /etc/flannel
    - /etc/systemd/system/flanneld.service.d
    - /etc/systemd/system/docker.service.d
  when: "K8S_MASTER == True or K8S_WORKER == True"

- name: Install flannel config
  become: True
  copy:
    content: |
      FLANNELD_IFACE={{ ansible_host }}
      FLANNELD_ETCD_ENDPOINTS={{ etcd2_endpoints | join(",") }}
    dest: /etc/flannel/options.env
    owner: root
    group: root
    mode: 0600
  when: "K8S_MASTER == True or K8S_WORKER == True"

- name: Install flanneld service on k8s nodes
  become: True
  copy:
    src: roles/common/files/flanneld.service.40-ExecStartPre-symlink.conf
    dest: /etc/systemd/system/flanneld.service.d/40-ExecStartPre-symlink.conf
  register: result
  when: "K8S_MASTER == True or K8S_WORKER == True"

- name: Install docker flanneld drop-in
  become: True
  copy:
    src: roles/common/files/docker.service.40-flannel.conf
    dest: /etc/systemd/system/docker.service.d/40-flannel.conf
  when: "K8S_MASTER == True or K8S_WORKER == True"

- name: Restart docker daemon
  become: True
  command: systemctl restart docker.service
  when: "K8S_MASTER == True or K8S_WORKER == True"
  # TODO: We should restart when we really changed something

- name: Get current k8s binary info
  become: True
  stat:
    path: /opt/bin/kubelet
  register: k8sbinary_file
  when: "K8S_MASTER == True or K8S_WORKER == True"

- name: Check if k8s binary is correct
  become: True
  set_fact:
    force_new_download: "{{ k8sbinary_file.stat.exists == False or k8sbinary_file.stat.md5 != K8S_KUBELET_MD5 }}"
  when: "K8S_MASTER == True or K8S_WORKER == True"

- name: Stop kubelet service
  become: True
  command: systemctl stop kubelet.service
  when: "(K8S_MASTER == True or K8S_WORKER == True) and force_new_download"
  # The service might not be installed yet, so we don't mind having errors
  ignore_errors: True

- name: Install k8s binary
  become: True
  get_url:
    url: http://dist/storage/Kubernetes/kubernetes-{{ K8S_VERSION }}-server-linux-amd64/server/bin/kubelet
    dest: /opt/bin/kubelet
    checksum: "md5:{{ K8S_KUBELET_MD5 }}"
    owner: root
    group: root
    mode: 0755
  when: "(K8S_MASTER == True or K8S_WORKER == True) and force_new_download"

- name: Install k8s worker certificates
  become: True
  copy:
    src: roles/k8s_vars/certs/{{ item }}
    dest: /etc/kubernetes/ssl/{{ item }}
    owner: root
    group: root
    mode: 0600
  with_items:
    - worker.pem
    - worker-key.pem
    - ca.pem
  when: K8S_WORKER

- name: Install k8s master certificates
  become: True
  copy:
    src: roles/k8s_vars/certs/{{ item }}
    dest: /etc/kubernetes/ssl/{{ item }}
    owner: root
    group: root
    mode: 0600
  with_items:
    - apiserver.pem
    - apiserver-key.pem
    - ca.pem
  when: K8S_MASTER

- name: Install k8s master manifests
  become: True
  template:
    src: "{{ item }}.j2"
    dest: /etc/kubernetes/manifests/{{ item }}
    owner: root
    group: root
    mode: 0755
  with_items:
    - kube-controller-manager.yaml
    - kube-proxy.yaml
    - kube-scheduler.yaml
    - kube-apiserver.yaml
  when: K8S_MASTER

- name: Install k8s worker proxy
  become: True
  template:
    src: kube-proxy-worker.yaml.j2
    dest: /etc/kubernetes/manifests/kube-proxy.yaml
    owner: root
    group: root
    mode: 0755
  when: K8S_WORKER

- name: Install k8s worker manifest
  become: True
  copy:
    src: worker-kubeconfig.yaml
    dest: /etc/kubernetes/worker-kubeconfig.yaml
    owner: root
    group: root
    mode: 0755
  when: K8S_WORKER

- name: Install k8s service
  become: True
  copy:
    # TODO: Make this a template
    # TODO: Should we enable this unit as well? Not sure how it's working right now :-(
    content: |
      [Service]
      ExecStart=/opt/bin/kubelet \
        --api_servers={% if K8S_MASTER %}http://127.0.0.1:8080{%else%}https://{{ k8s_masters | join(",") }}{% endif %} \
      {% if K8S_MASTER %}
        --register-schedulable=false \
      {%else%}
        --register-node=true \
      {% endif %}
        --allow-privileged=true \
        --config=/etc/kubernetes/manifests \
        --hostname-override={{ ansible_host }} \
        --cluster_dns=10.3.0.10 \
        --cluster_domain=cluster.local \
        --cadvisor-port=4194{% if not K8S_MASTER %} \
        --kubeconfig=/etc/kubernetes/worker-kubeconfig.yaml \
        --tls-cert-file=/etc/kubernetes/ssl/worker.pem \
        --tls-private-key-file=/etc/kubernetes/ssl/worker-key.pem{% endif %}

      Restart=always
      RestartSec=10

      [Install]
      WantedBy=multi-user.target
    dest: /etc/systemd/system/kubelet.service
    owner: root
    group: root
    mode: 0644
  when: "K8S_MASTER == True or K8S_WORKER == True"
  register: kservice

- name: Reload services
  become: True
  command: systemctl daemon-reload
  when: "(K8S_MASTER == True or K8S_WORKER == True) and kservice.changed"

- name: Restart k8s service if needed
  become: True
  command: systemctl restart kubelet.service
  when: "(K8S_MASTER == True or K8S_WORKER == True) and (kservice.changed or force_new_download)"

- name: Do not install k8s services on non k8s nodes
  # TODO: We should probably do "systemd reset-failed" or something along
  # those lines if this task is executed to make sure
  # the service is stopped/removed if it was running
  become: True
  file:
    path: "{{ item }}"
    state: absent
  with_items:
    - /etc/systemd/system/kubelet.service
    - /opt/bin/kubelet
    - /etc/kubernetes
  when: "K8S_MASTER == False and K8S_WORKER == False"
